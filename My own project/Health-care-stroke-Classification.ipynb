{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "666589bd-ef88-4ac5-a5a9-4eb13743f793",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting xgboost\n",
      "  Using cached xgboost-2.1.4-py3-none-win_amd64.whl.metadata (2.1 kB)\n",
      "Requirement already satisfied: numpy in c:\\users\\tienq\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from xgboost) (2.2.3)\n",
      "Requirement already satisfied: scipy in c:\\users\\tienq\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from xgboost) (1.15.2)\n",
      "Using cached xgboost-2.1.4-py3-none-win_amd64.whl (124.9 MB)\n",
      "Installing collected packages: xgboost\n",
      "Successfully installed xgboost-2.1.4\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "189be96f-a464-419b-a177-846b1fde053e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, precision_recall_curve\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import label_binarize\n",
    "import xgboost as xgb\n",
    "import joblib\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# ========================\n",
    "# 1. Data Loading & Exploration\n",
    "# ========================\n",
    "\n",
    "def load_and_explore_data(file_path):   \n",
    "    # Load the data\n",
    "    df = pd.read_csv(file_path)\n",
    "\n",
    "    # Display basic information\n",
    "    # print(f\"Dataset shape: {df.shape}\")\n",
    "    # print(\"\\nFirst 5 rows:\")\n",
    "    # print(df.head())\n",
    "\n",
    "    # Check for missing values\n",
    "    missing_values = df.isnull().sum()\n",
    "    print(\"\\nMissing values per column:\")\n",
    "    print(missing_values[missing_values > 0])\n",
    "\n",
    "    # Data types\n",
    "    # print(\"\\nData types:\")\n",
    "    # print(df.dtypes)\n",
    "    print(\"\\nBreakdown of activities:\")\n",
    "    print(df.stroke.value_counts())\n",
    "\n",
    "    # Summary statistics\n",
    "    print(\"\\nSummary statistics:\")\n",
    "    print(df.describe())\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0bab9c8-c581-4ce4-91bd-efc8be89d4bc",
   "metadata": {},
   "source": [
    "Scikit learn classifiers won't accept a sparse matrix for the prediction column. Thus, either `LabelEncoder` needs to be used to convert the activity labels to integers, or if `DictVectorizer` is used, the resulting matrix must be converted to a non-sparse array.  \n",
    "Use `LabelEncoder` to fit_transform the \"Activity\" column, and look at 5 random values.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f9dcd182-db54-4141-be81-dc925c8653bd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# le = LabelEncoder()\n",
    "# df['stroke'] = le.fit_transform(df.stroke)\n",
    "# df['stroke'].sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5674e343-78ef-43ef-87d2-479abd761ceb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Engineering features...\n"
     ]
    }
   ],
   "source": [
    "# ========================\n",
    "# 2. Feature Engineering\n",
    "# ========================\n",
    "\n",
    "# def engineer_features(df):\n",
    "\"\"\"\n",
    "Create features that might be predictive of wasteful spending\n",
    "\"\"\"\n",
    "print(\"\\nEngineering features...\")\n",
    "\n",
    "# # Make a copy to avoid modifying the original dataframe\n",
    "# df_processed = df.copy()\n",
    "\n",
    "# # Example features that might indicate wasteful spending\n",
    "\n",
    "# # 1. Price deviation from category average\n",
    "# # Group by category and calculate mean price\n",
    "# category_avg_price = df_processed.groupby('item_category')['price'].transform('mean')\n",
    "# df_processed['price_deviation'] = (df_processed['price'] - category_avg_price) / category_avg_price\n",
    "\n",
    "# # 2. Rush orders (if order_date and required_date fields exist)\n",
    "# if 'order_date' in df_processed.columns and 'required_date' in df_processed.columns:\n",
    "#     df_processed['order_date'] = pd.to_datetime(df_processed['order_date'])\n",
    "#     df_processed['required_date'] = pd.to_datetime(df_processed['required_date'])\n",
    "#     df_processed['lead_time'] = (df_processed['required_date'] - df_processed['order_date']).dt.days\n",
    "#     df_processed['is_rush_order'] = df_processed['lead_time'] < 5  # Define rush orders as < 5 days\n",
    "\n",
    "# # 3. End of budget period purchases (if date field exists)\n",
    "# if 'order_date' in df_processed.columns:\n",
    "#     df_processed['month'] = df_processed['order_date'].dt.month\n",
    "#     df_processed['is_end_of_quarter'] = df_processed['month'].isin([3, 6, 9, 12])\n",
    "\n",
    "# # 4. Unusual quantities\n",
    "# quantity_avg = df_processed.groupby('item_category')['quantity'].transform('mean')\n",
    "# quantity_std = df_processed.groupby('item_category')['quantity'].transform('std')\n",
    "# df_processed['quantity_zscore'] = (df_processed['quantity'] - quantity_avg) / quantity_std\n",
    "\n",
    "# # 5. Weekend orders (if date field exists)\n",
    "# if 'order_date' in df_processed.columns:\n",
    "#     df_processed['is_weekend'] = df_processed['order_date'].dt.dayofweek >= 5\n",
    "\n",
    "# # 6. Unusual supplier choices\n",
    "# # Count how often each supplier is used for each category\n",
    "# supplier_category_counts = df_processed.groupby(['supplier_id', 'item_category']).size().reset_index(name='counts')\n",
    "# common_suppliers = supplier_category_counts.groupby('item_category')['supplier_id'].apply(list).to_dict()\n",
    "\n",
    "# # Mark orders with uncommon suppliers\n",
    "# df_processed['is_uncommon_supplier'] = False\n",
    "# for idx, row in df_processed.iterrows():\n",
    "#     category = row['item_category']\n",
    "#     supplier = row['supplier_id']\n",
    "#     if category in common_suppliers:\n",
    "#         category_suppliers = common_suppliers[category]\n",
    "#         # If this supplier is not among the top suppliers for this category\n",
    "#         if supplier not in category_suppliers[:3]:  # Assuming top 3 are common\n",
    "#             df_processed.at[idx, 'is_uncommon_supplier'] = True\n",
    "\n",
    "# print(\"Engineered features preview:\")\n",
    "# new_columns = [col for col in df_processed.columns if col not in df.columns]\n",
    "# print(df_processed[new_columns].head())\n",
    "\n",
    "# return df_processed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d6f885ab-d83c-47ad-9e20-cc86f122c1c4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ========================\n",
    "# 3. Data Preprocessing\n",
    "# ========================\n",
    "\n",
    "def preprocess_data(df, target_column='Activity'):\n",
    "    \"\"\"\n",
    "    Prepare data for machine learning\n",
    "    \"\"\"\n",
    "    print(\"\\nPreprocessing data for machine learning...\")\n",
    "\n",
    "    # Separate features and target\n",
    "    X = df.drop(columns=['stroke'])\n",
    "    y = df['stroke']\n",
    "\n",
    "    # Identify categorical and numerical columns\n",
    "    categorical_cols = X.select_dtypes(include=['object', 'category', 'bool']).columns.tolist()\n",
    "    numerical_cols = X.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "\n",
    "    # print(f\"Categorical columns: {categorical_cols}\")\n",
    "    # print(f\"Numerical columns: {numerical_cols}\")\n",
    "\n",
    "    # Create preprocessing pipeline\n",
    "    numerical_transformer = Pipeline(steps=[\n",
    "        ('imputer', SimpleImputer(strategy='median')), \n",
    "        ('scaler', StandardScaler())\n",
    "    ])\n",
    "\n",
    "    categorical_transformer = Pipeline(steps=[\n",
    "        ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "        ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "    ])\n",
    "\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('num', numerical_transformer, numerical_cols),\n",
    "            ('cat', categorical_transformer, categorical_cols)\n",
    "        ])\n",
    "\n",
    "    # Split the data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "    print(f\"Training set shape: {X_train.shape}\")\n",
    "    print(f\"Testing set shape: {X_test.shape}\")\n",
    "\n",
    "    return X_train, X_test, y_train, y_test, preprocessor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "12569996-11e0-44ef-83ab-5955896f2e46",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ========================\n",
    "# 4. Model Training and Evaluation\n",
    "# ========================\n",
    "\n",
    "def train_and_evaluate_models(X_train, X_test, y_train, y_test, preprocessor):\n",
    "    \"\"\"\n",
    "    Train multiple models and evaluate their performance\n",
    "    \"\"\"\n",
    "    print(\"\\nTraining and evaluating models...\")\n",
    "\n",
    "    # Define models to try\n",
    "    models = {\n",
    "        'Logistic Regression': Pipeline([\n",
    "            ('preprocessor', preprocessor),\n",
    "            ('classifier', LogisticRegression(max_iter=1000, solver='liblinear', class_weight='balanced'))\n",
    "        ]),\n",
    "\n",
    "        'Random Forest': Pipeline([\n",
    "            ('preprocessor', preprocessor),\n",
    "            ('classifier', RandomForestClassifier(n_estimators=100, class_weight='balanced', random_state=42))\n",
    "        ]),\n",
    "\n",
    "        'Gradient Boosting': Pipeline([\n",
    "            ('preprocessor', preprocessor),\n",
    "            ('classifier', GradientBoostingClassifier(n_estimators=100, random_state=42))\n",
    "        ]),\n",
    "\n",
    "        'XGBoost': Pipeline([\n",
    "            ('preprocessor', preprocessor),\n",
    "            ('classifier', xgb.XGBClassifier(n_estimators=100, use_label_encoder=False, eval_metric='logloss', random_state=42))\n",
    "        ])\n",
    "    }\n",
    "\n",
    "    # Results storage\n",
    "    model_results = {}\n",
    "\n",
    "    # Train and evaluate each model\n",
    "    for name, model in models.items():\n",
    "        print(f\"\\nTraining {name}...\")\n",
    "\n",
    "        # Train model\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        # Make predictions\n",
    "        y_pred = model.predict(X_test)\n",
    "        y_prob = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "        # For binary classification, ensure y_prob has two columns\n",
    "        if y_prob.ndim == 1:\n",
    "            # Convert 1D array to 2D: [P(class 0), P(class 1)]\n",
    "            y_prob = np.vstack([1 - y_prob, y_prob]).T\n",
    "\n",
    "        # Calculate metrics\n",
    "        accuracy = model.score(X_test, y_test)\n",
    "        report = classification_report(y_test, y_pred)\n",
    "        conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "        # Adjust roc_auc_score for multiclass\n",
    "        if len(np.unique(y_test)) == 2:  # Binary classification\n",
    "            roc_auc = roc_auc_score(y_test, y_prob[:, 1])\n",
    "        else:  # Multiclass classification\n",
    "            roc_auc = roc_auc_score(label_binarize(y_test, classes=[0,1,2,3,4,5]),\n",
    "                                    y_prob, \n",
    "                                    average='weighted')\n",
    "\n",
    "        # Cross-validation score\n",
    "        cv_score = cross_val_score(model, pd.concat([X_train, X_test]), \n",
    "                                pd.concat([y_train, y_test]), \n",
    "                                cv=5, scoring='roc_auc').mean()\n",
    "\n",
    "        # Store results\n",
    "        model_results[name] = {\n",
    "            'model': model,\n",
    "            'accuracy': accuracy,\n",
    "            'classification_report': report,\n",
    "            'confusion_matrix': conf_matrix,\n",
    "            'roc_auc': roc_auc,\n",
    "            'cv_score': cv_score\n",
    "        }\n",
    "\n",
    "        # Print results\n",
    "        print(f\"{name} Results:\")\n",
    "        print(f\"Accuracy: {accuracy:.4f}\")\n",
    "        print(f\"ROC AUC: {roc_auc:.4f}\")\n",
    "        print(f\"5-Fold CV ROC AUC: {cv_score:.4f}\")\n",
    "        print(\"Classification Report:\")\n",
    "        print(report)\n",
    "\n",
    "    # Find best model based on ROC AUC\n",
    "    best_model_name = max(model_results, key=lambda x: model_results[x]['roc_auc'])\n",
    "    print(f\"\\nBest model: {best_model_name} with ROC AUC of {model_results[best_model_name]['roc_auc']:.4f}\")\n",
    "\n",
    "    return model_results, best_model_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e31d4e4b-a0c5-4cdf-a2bd-c8d350caa2e8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ========================\n",
    "# 5. Feature Importance Analysis\n",
    "# ========================\n",
    "\n",
    "def analyze_feature_importance(model_results, best_model_name, X_train, preprocessor):\n",
    "    \"\"\"\n",
    "    Analyze and visualize feature importance for the best model\n",
    "    \"\"\"\n",
    "    print(\"\\nAnalyzing feature importance...\")\n",
    "\n",
    "    best_model = model_results[best_model_name]['model']\n",
    "\n",
    "    # For tree-based models\n",
    "    if best_model_name in ['Random Forest', 'Gradient Boosting', 'XGBoost']:\n",
    "        # Get the trained model from the pipeline\n",
    "        model = best_model.named_steps['classifier']\n",
    "        \n",
    "        # Get feature names after preprocessing\n",
    "        if hasattr(preprocessor, 'transformers_'):\n",
    "            # Get column names from the preprocessor\n",
    "            cat_cols = preprocessor.transformers_[1][2]  # Categorical columns\n",
    "            cat_transformer = preprocessor.transformers_[1][1]  # Categorical transformer\n",
    "            \n",
    "            # Get the one-hot encoder from the categorical transformer\n",
    "            if 'onehot' in cat_transformer.named_steps:\n",
    "                onehot = cat_transformer.named_steps['onehot']\n",
    "                if hasattr(onehot, 'get_feature_names_out'):\n",
    "                    cat_features = onehot.get_feature_names_out(cat_cols)\n",
    "                else:\n",
    "                    cat_features = [f\"{col}_{val}\" for col in cat_cols for val in onehot.categories_[cat_cols.index(col)]]\n",
    "            else:\n",
    "                cat_features = cat_cols\n",
    "                \n",
    "            num_cols = preprocessor.transformers_[0][2]  # Numerical columns\n",
    "            all_features = list(num_cols) + list(cat_features)\n",
    "        else:\n",
    "            all_features = [f\"Feature_{i}\" for i in range(X_train.shape[1])]\n",
    "        \n",
    "        # Extract feature importances\n",
    "        importances = model.feature_importances_\n",
    "        \n",
    "        # Match feature importances with feature names\n",
    "        if len(importances) == len(all_features):\n",
    "            feature_importance = pd.DataFrame({\n",
    "                'Feature': all_features,\n",
    "                'Importance': importances\n",
    "            }).sort_values('Importance', ascending=False)\n",
    "            \n",
    "            # Display top 15 features\n",
    "            top_features = feature_importance.head(15)\n",
    "            print(\"\\nTop 15 features:\")\n",
    "            print(top_features)\n",
    "            \n",
    "            # Plot feature importance\n",
    "            plt.figure(figsize=(12, 8))\n",
    "            sns.barplot(x='Importance', y='Feature', data=top_features)\n",
    "            plt.title(f'Top 15 Feature Importances for {best_model_name}')\n",
    "            plt.tight_layout()\n",
    "            plt.savefig('feature_importance.png')\n",
    "            plt.close()\n",
    "            \n",
    "            print(\"Feature importance plot saved as 'feature_importance.png'\")\n",
    "            \n",
    "            # return feature_importance\n",
    "\n",
    "    # For logistic regression\n",
    "    elif best_model_name == 'Logistic Regression':\n",
    "        print(\"Feature importance analysis for Logistic Regression is not implemented in this example.\")\n",
    "\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ff3255ae-ea87-4b10-b3da-f8912980c378",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ========================\n",
    "# 6. Model Optimization\n",
    "# ========================\n",
    "\n",
    "def optimize_best_model(best_model_name, X_train, y_train, X_test, y_test, preprocessor):\n",
    "    \"\"\"\n",
    "    Optimize the best model using hyperparameter tuning\n",
    "    \"\"\"\n",
    "    print(f\"\\nOptimizing {best_model_name} with hyperparameter tuning...\")\n",
    "\n",
    "    param_grid = {}\n",
    "\n",
    "    if best_model_name == 'Logistic Regression':\n",
    "        param_grid = {\n",
    "            'classifier__C': [0.01, 0.1, 1, 10, 100],\n",
    "            'classifier__penalty': ['l1', 'l2'],\n",
    "            'classifier__solver': ['liblinear', 'saga']\n",
    "        }\n",
    "\n",
    "    elif best_model_name == 'Random Forest':\n",
    "        param_grid = {\n",
    "            'classifier__n_estimators': [50, 100, 200],\n",
    "            'classifier__max_depth': [None, 10, 20, 30],\n",
    "            'classifier__min_samples_split': [2, 5, 10],\n",
    "            'classifier__min_samples_leaf': [1, 2, 4]\n",
    "        }\n",
    "\n",
    "    elif best_model_name == 'Gradient Boosting':\n",
    "        param_grid = {\n",
    "            'classifier__n_estimators': [50, 100, 200],\n",
    "            'classifier__learning_rate': [0.01, 0.1, 0.2],\n",
    "            'classifier__max_depth': [3, 5, 7],\n",
    "            'classifier__min_samples_split': [2, 5]\n",
    "        }\n",
    "\n",
    "    elif best_model_name == 'XGBoost':\n",
    "        param_grid = {\n",
    "            'classifier__n_estimators': [50, 100, 200],\n",
    "            'classifier__learning_rate': [0.01, 0.1, 0.2],\n",
    "            'classifier__max_depth': [3, 5, 7],\n",
    "            'classifier__subsample': [0.8, 0.9, 1.0],\n",
    "            'classifier__colsample_bytree': [0.8, 0.9, 1.0]\n",
    "        }\n",
    "\n",
    "    # Create base model pipeline\n",
    "    base_model = None\n",
    "    if best_model_name == 'Logistic Regression':\n",
    "        base_model = Pipeline([\n",
    "            ('preprocessor', preprocessor),\n",
    "            ('classifier', LogisticRegression(max_iter=1000, class_weight='balanced'))\n",
    "        ])\n",
    "    elif best_model_name == 'Random Forest':\n",
    "        base_model = Pipeline([\n",
    "            ('preprocessor', preprocessor),\n",
    "            ('classifier', RandomForestClassifier(class_weight='balanced', random_state=42))\n",
    "        ])\n",
    "    elif best_model_name == 'Gradient Boosting':\n",
    "        base_model = Pipeline([\n",
    "            ('preprocessor', preprocessor),\n",
    "            ('classifier', GradientBoostingClassifier(random_state=42))\n",
    "        ])\n",
    "    elif best_model_name == 'XGBoost':\n",
    "        base_model = Pipeline([\n",
    "            ('preprocessor', preprocessor),\n",
    "            ('classifier', xgb.XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42))\n",
    "        ])\n",
    "\n",
    "    # Perform grid search\n",
    "    if base_model is not None and param_grid:\n",
    "        grid_search = GridSearchCV(\n",
    "            base_model,\n",
    "            param_grid,\n",
    "            cv=5,\n",
    "            scoring='roc_auc',\n",
    "            n_jobs=-1,\n",
    "            verbose=1\n",
    "        )\n",
    "        \n",
    "        grid_search.fit(X_train, y_train)\n",
    "        \n",
    "        # Get best parameters and model\n",
    "        best_params = grid_search.best_params_\n",
    "        best_model = grid_search.best_estimator_\n",
    "        \n",
    "        # Evaluate optimized model\n",
    "        y_pred = best_model.predict(X_test)\n",
    "        y_prob = best_model.predict_proba(X_test)[:, 1]\n",
    "        \n",
    "        accuracy = best_model.score(X_test, y_test)\n",
    "        report = classification_report(y_test, y_pred)\n",
    "        conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "        roc_auc = roc_auc_score(y_test, y_prob)\n",
    "        \n",
    "        print(f\"\\nOptimized {best_model_name} Results:\")\n",
    "        print(f\"Best Parameters: {best_params}\")\n",
    "        print(f\"Accuracy: {accuracy:.4f}\")\n",
    "        print(f\"ROC AUC: {roc_auc:.4f}\")\n",
    "        print(\"Classification Report:\")\n",
    "        print(report)\n",
    "        \n",
    "        return best_model, best_params\n",
    "\n",
    "    print(\"Optimization not applicable for the selected model.\")\n",
    "    return None, None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "0af1b8df-893d-46d1-9cb0-10f5f767aad2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ========================\n",
    "# 7. Save Model\n",
    "# ========================\n",
    "\n",
    "def save_model(model, file_path='wasteful_procurement_model.pkl'):\n",
    "    \"\"\"\n",
    "    Save the trained model to a file\n",
    "    \"\"\"\n",
    "    print(f\"\\nSaving model to {file_path}...\")\n",
    "    joblib.dump(model, file_path)\n",
    "    print(\"Model saved successfully.\")\n",
    "\n",
    "# ========================\n",
    "# 8. Create Wasteful Purchase Detection Function\n",
    "# ========================\n",
    "\n",
    "def detect_wasteful_purchases(model, new_data, threshold=0.5):\n",
    "    \"\"\"\n",
    "    Detect potentially wasteful purchases in new procurement data\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    model : sklearn.pipeline.Pipeline\n",
    "        Trained model pipeline\n",
    "    new_data : pandas.DataFrame\n",
    "        New procurement data to evaluate\n",
    "    threshold : float, default=0.5\n",
    "        Probability threshold for classifying as wasteful\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    pandas.DataFrame\n",
    "        Original data with added wasteful prediction and probability columns\n",
    "    \"\"\"\n",
    "    print(\"\\nDetecting potentially wasteful purchases...\")\n",
    "    \n",
    "    # Make a copy of the input data\n",
    "    result_df = new_data.copy()\n",
    "    \n",
    "    # Make predictions\n",
    "    probabilities = model.predict_proba(new_data)[:, 1]\n",
    "    predictions = (probabilities >= threshold).astype(int)\n",
    "    \n",
    "    # Add predictions to the dataframe\n",
    "    result_df['wasteful_probability'] = probabilities\n",
    "    result_df['is_wasteful_predicted'] = predictions\n",
    "    \n",
    "    # Sort by probability (highest first)\n",
    "    result_df = result_df.sort_values('wasteful_probability', ascending=False)\n",
    "    \n",
    "    # Summary statistics\n",
    "    total_purchases = len(result_df)\n",
    "    wasteful_purchases = sum(predictions)\n",
    "    wasteful_percentage = (wasteful_purchases / total_purchases) * 100\n",
    "    \n",
    "    print(f\"Total purchases evaluated: {total_purchases}\")\n",
    "    print(f\"Potentially wasteful purchases detected: {wasteful_purchases} ({wasteful_percentage:.2f}%)\")\n",
    "    \n",
    "    return result_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "761bf02f-0d58-4767-81b5-a50dcf73e4f0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting wasteful procurement detection pipeline...\n",
      "\n",
      "Missing values per column:\n",
      "bmi    201\n",
      "dtype: int64\n",
      "\n",
      "Breakdown of activities:\n",
      "stroke\n",
      "0    4861\n",
      "1     249\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Summary statistics:\n",
      "                 id          age  hypertension  heart_disease  \\\n",
      "count   5110.000000  5110.000000   5110.000000    5110.000000   \n",
      "mean   36517.829354    43.226614      0.097456       0.054012   \n",
      "std    21161.721625    22.612647      0.296607       0.226063   \n",
      "min       67.000000     0.080000      0.000000       0.000000   \n",
      "25%    17741.250000    25.000000      0.000000       0.000000   \n",
      "50%    36932.000000    45.000000      0.000000       0.000000   \n",
      "75%    54682.000000    61.000000      0.000000       0.000000   \n",
      "max    72940.000000    82.000000      1.000000       1.000000   \n",
      "\n",
      "       avg_glucose_level          bmi       stroke  \n",
      "count        5110.000000  4909.000000  5110.000000  \n",
      "mean          106.147677    28.893237     0.048728  \n",
      "std            45.283560     7.854067     0.215320  \n",
      "min            55.120000    10.300000     0.000000  \n",
      "25%            77.245000    23.500000     0.000000  \n",
      "50%            91.885000    28.100000     0.000000  \n",
      "75%           114.090000    33.100000     0.000000  \n",
      "max           271.740000    97.600000     1.000000  \n",
      "\n",
      "Preprocessing data for machine learning...\n",
      "Training set shape: (4088, 11)\n",
      "Testing set shape: (1022, 11)\n",
      "\n",
      "Training and evaluating models...\n",
      "\n",
      "Training Logistic Regression...\n",
      "Logistic Regression Results:\n",
      "Accuracy: 0.7495\n",
      "ROC AUC: 0.8413\n",
      "5-Fold CV ROC AUC: 0.8386\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.75      0.85       972\n",
      "           1       0.14      0.80      0.24        50\n",
      "\n",
      "    accuracy                           0.75      1022\n",
      "   macro avg       0.56      0.77      0.54      1022\n",
      "weighted avg       0.94      0.75      0.82      1022\n",
      "\n",
      "\n",
      "Training Random Forest...\n",
      "Random Forest Results:\n",
      "Accuracy: 0.9511\n",
      "ROC AUC: 0.7815\n",
      "5-Fold CV ROC AUC: 0.8035\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      1.00      0.97       972\n",
      "           1       0.00      0.00      0.00        50\n",
      "\n",
      "    accuracy                           0.95      1022\n",
      "   macro avg       0.48      0.50      0.49      1022\n",
      "weighted avg       0.90      0.95      0.93      1022\n",
      "\n",
      "\n",
      "Training Gradient Boosting...\n",
      "Gradient Boosting Results:\n",
      "Accuracy: 0.9472\n",
      "ROC AUC: 0.8217\n",
      "5-Fold CV ROC AUC: 0.8333\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.99      0.97       972\n",
      "           1       0.17      0.02      0.04        50\n",
      "\n",
      "    accuracy                           0.95      1022\n",
      "   macro avg       0.56      0.51      0.50      1022\n",
      "weighted avg       0.91      0.95      0.93      1022\n",
      "\n",
      "\n",
      "Training XGBoost...\n",
      "XGBoost Results:\n",
      "Accuracy: 0.9423\n",
      "ROC AUC: 0.8023\n",
      "5-Fold CV ROC AUC: 0.8089\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.99      0.97       972\n",
      "           1       0.15      0.04      0.06        50\n",
      "\n",
      "    accuracy                           0.94      1022\n",
      "   macro avg       0.55      0.51      0.52      1022\n",
      "weighted avg       0.91      0.94      0.93      1022\n",
      "\n",
      "\n",
      "Best model: Logistic Regression with ROC AUC of 0.8413\n",
      "\n",
      "Analyzing feature importance...\n",
      "Feature importance analysis for Logistic Regression is not implemented in this example.\n",
      "\n",
      "Optimizing Logistic Regression with hyperparameter tuning...\n",
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n",
      "\n",
      "Optimized Logistic Regression Results:\n",
      "Best Parameters: {'classifier__C': 0.01, 'classifier__penalty': 'l1', 'classifier__solver': 'liblinear'}\n",
      "Accuracy: 0.7065\n",
      "ROC AUC: 0.8404\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.70      0.82       972\n",
      "           1       0.13      0.84      0.22        50\n",
      "\n",
      "    accuracy                           0.71      1022\n",
      "   macro avg       0.56      0.77      0.52      1022\n",
      "weighted avg       0.95      0.71      0.79      1022\n",
      "\n",
      "\n",
      "Saving model to wasteful_procurement_model.pkl...\n",
      "Model saved successfully.\n",
      "\n",
      "Wasteful procurement detection pipeline completed successfully!\n"
     ]
    }
   ],
   "source": [
    "# ========================\n",
    "# 9. Main Function\n",
    "# ========================\n",
    "\n",
    "def main():\n",
    "    \"\"\"\n",
    "    Main function to run the entire pipeline\n",
    "    \"\"\"\n",
    "    print(\"Starting wasteful procurement detection pipeline...\")\n",
    "    \n",
    "    # Sample usage - in practice, replace with your actual data file\n",
    "    data_file = \"healthcare-dataset-stroke-data.csv\"\n",
    "    \n",
    "    try:\n",
    "        # Load and explore data\n",
    "        df = load_and_explore_data(data_file)\n",
    "        \n",
    "        # # Engineer features\n",
    "        # df_processed = engineer_features(df)\n",
    "        \n",
    "        # Preprocess data\n",
    "        X_train, X_test, y_train, y_test, preprocessor = preprocess_data(df)\n",
    "        \n",
    "        # Train and evaluate models\n",
    "        model_results, best_model_name = train_and_evaluate_models(X_train, X_test, y_train, y_test, preprocessor)\n",
    "        \n",
    "        # Analyze feature importance\n",
    "        feature_importance = analyze_feature_importance(model_results, best_model_name, X_train, preprocessor)\n",
    "        \n",
    "        # Optimize the best model\n",
    "        optimized_model, best_params = optimize_best_model(best_model_name, X_train, y_train, X_test, y_test, preprocessor)\n",
    "        \n",
    "        # Save the optimized model\n",
    "        if optimized_model is not None:\n",
    "            save_model(optimized_model)\n",
    "        else:\n",
    "            save_model(model_results[best_model_name]['model'])\n",
    "        \n",
    "        print(\"\\nWasteful procurement detection pipeline completed successfully!\")\n",
    "        \n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: Data file '{data_file}' not found. Please provide a valid file path.\")\n",
    "        print(\"This script expects a CSV file with procurement data including features like:\")\n",
    "        print(\"- item_category: Category of purchased item\")\n",
    "        print(\"- price: Cost of the item\")\n",
    "        print(\"- quantity: Number of items purchased\")\n",
    "        print(\"- supplier_id: ID of the supplier\")\n",
    "        print(\"- order_date: Date when order was placed (optional)\")\n",
    "        print(\"- required_date: Date when item is needed (optional)\")\n",
    "        print(\"- is_wasteful: Target variable indicating wasteful purchase (1/0)\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error: An unexpected error occurred: {str(e)}\")\n",
    "\n",
    "# Example of how to use the model for new data\n",
    "def example_usage():\n",
    "    \"\"\"\n",
    "    Example of how to use the trained model\n",
    "    \"\"\"\n",
    "    # Load the trained model\n",
    "    model = joblib.load('wasteful_procurement_model.pkl')\n",
    "    \n",
    "    # Load new procurement data\n",
    "    new_data = pd.read_csv('new_procurement_data.csv')\n",
    "    \n",
    "    # Engineer features for new data (same as in training)\n",
    "    new_data_processed = engineer_features(new_data)\n",
    "    \n",
    "    # Drop the target column if it exists in the new data\n",
    "    if 'is_wasteful' in new_data_processed.columns:\n",
    "        new_data_processed = new_data_processed.drop(columns=['is_wasteful'])\n",
    "    \n",
    "    # Detect wasteful purchases\n",
    "    results = detect_wasteful_purchases(model, new_data_processed, threshold=0.7)\n",
    "    \n",
    "    # Save the results\n",
    "    results.to_csv('wasteful_purchase_predictions.csv', index=False)\n",
    "    \n",
    "    # Display top 10 most likely wasteful purchases\n",
    "    print(\"\\nTop 10 most likely wasteful purchases:\")\n",
    "    print(results.head(10)[['item_category', 'price', 'quantity', 'wasteful_probability']])\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "    # Uncomment to run example usage\n",
    "    # example_usage()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
